{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1j5TdqsaY0w",
        "outputId": "0fb54240-7cf8-44a9-bd79-b84b82206910"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "portaudio19-dev is already the newest version (19.6.0-1.1).\n",
            "python3-pyaudio is already the newest version (0.2.11-1.3ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.12/dist-packages (3.14.3)\n",
            "Requirement already satisfied: pyaudio in /usr/lib/python3/dist-packages (0.2.11)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from SpeechRecognition) (4.15.0)\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y portaudio19-dev python3-pyaudio\n",
        "!pip install SpeechRecognition pyaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JxytQc1QZFZe",
        "outputId": "19ed7f6f-1a4d-4c36-d3f9-94eb3ceda3e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping langchain-google-genai as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "diffusers 0.35.2 requires huggingface-hub>=0.34.0, but you have huggingface-hub 0.23.5 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "datasets 4.0.0 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.23.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "gradio 5.49.1 requires huggingface-hub<2.0,>=0.33.5, but you have huggingface-hub 0.23.5 which is incompatible.\n",
            "peft 0.17.1 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.3)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (2.6.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<5.0.0,>=4.32.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<5.0.0,>=4.32.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<5.0.0,>=4.32.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<5.0.0,>=4.32.0->sentence-transformers) (2025.10.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Using cached numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-community 0.2.16 requires numpy<2.0.0,>=1.26.0; python_version >= \"3.12\", but you have numpy 2.3.4 which is incompatible.\n",
            "langchain 0.2.16 requires numpy<2.0.0,>=1.26.0; python_version >= \"3.12\", but you have numpy 2.3.4 which is incompatible.\n",
            "diffusers 0.35.2 requires huggingface-hub>=0.34.0, but you have huggingface-hub 0.23.5 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "datasets 4.0.0 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.23.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
            "gradio 5.49.1 requires huggingface-hub<2.0,>=0.33.5, but you have huggingface-hub 0.23.5 which is incompatible.\n",
            "peft 0.17.1 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.3.4\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "4bbb9eb8e8ee43c5bc4631d6cfb6f068",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip uninstall -y langchain langchain-community langchain-google-genai google-generativeai -q\n",
        "!pip install langchain==0.2.16 langchain-community==0.2.16 google-generativeai==0.7.2 chromadb sentence-transformers -q\n",
        "!pip install --upgrade pip\n",
        "!pip install sentence-transformers\n",
        "!pip install transformers\n",
        "!pip install numpy --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9vo4ZQCZcDJ",
        "outputId": "d44bf05f-4efc-4030-a3bf-7c7656b10b8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.3)\n",
            "Found existing installation: transformers 4.44.2\n",
            "Uninstalling transformers-4.44.2:\n",
            "  Successfully uninstalled transformers-4.44.2\n",
            "Found existing installation: huggingface-hub 0.23.5\n",
            "Uninstalling huggingface-hub-0.23.5:\n",
            "  Successfully uninstalled huggingface-hub-0.23.5\n",
            "Found existing installation: sentence-transformers 2.6.1\n",
            "Uninstalling sentence-transformers-2.6.1:\n",
            "  Successfully uninstalled sentence-transformers-2.6.1\n",
            "Collecting transformers==4.44.2\n",
            "  Using cached transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
            "Collecting huggingface-hub==0.23.5\n",
            "  Using cached huggingface_hub-0.23.5-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting sentence-transformers==2.6.1\n",
            "  Using cached sentence_transformers-2.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2.3.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.6.2)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.23.5) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.23.5) (4.15.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.6.1) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.6.1) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.6.1) (1.16.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.6.1) (11.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers==2.6.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers==2.6.1) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2025.10.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==2.6.1) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==2.6.1) (3.6.0)\n",
            "Using cached transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
            "Using cached huggingface_hub-0.23.5-py3-none-any.whl (402 kB)\n",
            "Using cached sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n",
            "Installing collected packages: huggingface-hub, transformers, sentence-transformers\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/3\u001b[0m [sentence-transformers]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "diffusers 0.35.2 requires huggingface-hub>=0.34.0, but you have huggingface-hub 0.23.5 which is incompatible.\n",
            "datasets 4.0.0 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.23.5 which is incompatible.\n",
            "gradio 5.49.1 requires huggingface-hub<2.0,>=0.33.5, but you have huggingface-hub 0.23.5 which is incompatible.\n",
            "peft 0.17.1 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.23.5 sentence-transformers-2.6.1 transformers-4.44.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -U pip\n",
        "!pip uninstall -y transformers huggingface-hub sentence-transformers\n",
        "!pip install transformers==4.44.2 huggingface-hub==0.23.5 sentence-transformers==2.6.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-afQKzJPZfAL"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXV53WiKACuJ"
      },
      "source": [
        "üß† LLM-Powered SQL Generation: Uses Gemini 2.0 Flash to convert plain English questions into optimized SQL queries.\n",
        "\n",
        "üíæ SQLite Integration: Connects to olist_sqlite.db, which contains all e-commerce tables.\n",
        "\n",
        "üó£Ô∏è Conversational Memory: Remembers the last few interactions, enabling follow-up questions like ‚Äúshow me those from last month.‚Äù\n",
        "\n",
        "‚öôÔ∏è Error Handling & Rate Limit Protection: Waits and retries when API limits are hit.\n",
        "\n",
        "üìú Interactive CLI Mode: Supports commands ‚Äî\n",
        "\n",
        "history ‚Üí show previous Q&A\n",
        "\n",
        "clear ‚Üí reset chat memory\n",
        "\n",
        "quit ‚Üí exit the session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        },
        "id": "zcd_qHUhZfP-",
        "outputId": "f55ac9c8-fdc7-4534-a57d-ee7f57aa34ef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4170683697.py:70: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
            "  embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-4170683697.py:83: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the langchain-chroma package and should be used instead. To use it run `pip install -U langchain-chroma` and import as `from langchain_chroma import Chroma`.\n",
            "  vs = Chroma(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Initializing Enhanced Multi-Agent System...\n",
            "‚úÖ Database: Connected\n",
            "‚úÖ ChromaDB: 4 collections\n",
            "‚úÖ Gemini API: Ready\n",
            "‚úÖ Voice Recognition: Ready\n",
            "üìÖ Dataset: Brazilian Olist e-commerce dataset (2016-2018): 100k orders from multiple marketplaces\n",
            "üÜï New Features: Voice Input, Enhanced Caching, Context Resolution\n",
            "\n",
            "üåê Launching Gradio UI...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://10671f7355fd5aa895.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://10671f7355fd5aa895.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://10671f7355fd5aa895.gradio.live\n"
          ]
        }
      ],
      "source": [
        "# ==================== MULTI-AGENT SYSTEM WITH VOICE & IMPROVEMENTS ====================\n",
        "\n",
        "import os\n",
        "import time\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import google.generativeai as genai\n",
        "from langchain_community.utilities import SQLDatabase\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "import re\n",
        "from datetime import datetime\n",
        "import gradio as gr\n",
        "from typing import Tuple, Optional, Dict, Any\n",
        "import io\n",
        "from PIL import Image\n",
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "import tempfile\n",
        "\n",
        "# ==================== CONFIG ====================\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"\"#ADD YOUR API KEY HERE \n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "# Set plotting style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Rate limit tracking\n",
        "api_calls_made = 0\n",
        "MAX_API_CALLS = 180\n",
        "\n",
        "# ==================== DATABASE ====================\n",
        "sqlite_path = \"/content/drive/MyDrive/archive/olist_sqlite.db\"#ADD YOUR SQLITE PATH HERE \n",
        "db = SQLDatabase.from_uri(f\"sqlite:///{sqlite_path}\")\n",
        "\n",
        "# ==================== SCHEMA INFO ====================\n",
        "SCHEMA_INFO = \"\"\"\n",
        "Tables and Columns:\n",
        "\n",
        "1. olist_customers_dataset (99,441 rows)\n",
        "   Columns: customer_id, customer_unique_id, customer_zip_code_prefix, customer_city, customer_state\n",
        "\n",
        "2. olist_order_payments_dataset (103,886 rows)\n",
        "   Columns: order_id, payment_sequential, payment_type, payment_installments, payment_value\n",
        "\n",
        "3. olist_order_items_dataset (112,650 rows)\n",
        "   Columns: order_id, order_item_id, product_id, seller_id, shipping_limit_date, price, freight_value\n",
        "\n",
        "4. olist_order_reviews_dataset (99,224 rows)\n",
        "   Columns: review_id, order_id, review_score, review_comment_title, review_comment_message, review_creation_date, review_answer_timestamp\n",
        "\n",
        "5. olist_sellers_dataset (3,095 rows)\n",
        "   Columns: seller_id, seller_zip_code_prefix, seller_city, seller_state\n",
        "\n",
        "6. product_category_name_translation (71 rows)\n",
        "   Columns: product_category_name, product_category_name_english\n",
        "\n",
        "7. olist_products_dataset (32,951 rows)\n",
        "   Columns: product_id, product_category_name, product_name_lenght, product_description_lenght, product_photos_qty, product_weight_g, product_length_cm, product_height_cm, product_width_cm\n",
        "\n",
        "8. olist_orders_dataset (99,441 rows)\n",
        "   Columns: order_id, customer_id, order_status, order_purchase_timestamp, order_approved_at, order_delivered_carrier_date, order_delivered_customer_date, order_estimated_delivery_date\n",
        "\"\"\"\n",
        "\n",
        "# ==================== CHROMADB SETUP ====================\n",
        "chroma_path = \"/content/drive/MyDrive/chroma_db_download\"#ADD YOUR CHROMADB PATH HERE \n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
        "\n",
        "vectorstores = {}\n",
        "collection_names = [\n",
        "    \"olist_order_reviews_dataset\",\n",
        "    \"olist_products_dataset\",\n",
        "    \"olist_order_items_dataset\",\n",
        "    \"product_category_name_translation\"\n",
        "]\n",
        "\n",
        "try:\n",
        "    for coll_name in collection_names:\n",
        "        try:\n",
        "            vs = Chroma(\n",
        "                persist_directory=chroma_path,\n",
        "                embedding_function=embedding_model,\n",
        "                collection_name=coll_name\n",
        "            )\n",
        "            test = vs.similarity_search(\"test\", k=1)\n",
        "            if test:\n",
        "                vectorstores[coll_name] = vs\n",
        "        except:\n",
        "            pass\n",
        "    vectorstores = vectorstores if vectorstores else None\n",
        "except:\n",
        "    vectorstores = None\n",
        "\n",
        "# ==================== GEMINI MODEL ====================\n",
        "model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "# ==================== ENHANCED MEMORY & CACHE ====================\n",
        "conversation_history = []\n",
        "result_cache = {\n",
        "    'last_sql_result': None,\n",
        "    'last_plot_path': None,\n",
        "    'last_sql_query': None,\n",
        "    'last_question': None,\n",
        "    'last_product_ids': [],\n",
        "    'last_order_ids': [],\n",
        "    'last_category': None,\n",
        "    'query_history': []  # Store last 5 queries\n",
        "}\n",
        "\n",
        "# Dataset info\n",
        "DATASET_START_YEAR = 2016\n",
        "DATASET_END_YEAR = 2018\n",
        "DATASET_INFO = f\"Brazilian Olist e-commerce dataset (2016-2018): 100k orders from multiple marketplaces\"\n",
        "\n",
        "# ==================== VOICE AGENT ====================\n",
        "def transcribe_audio(audio_path: str) -> Tuple[str, str]:\n",
        "    \"\"\"Transcribe audio to text using speech recognition\"\"\"\n",
        "    if audio_path is None:\n",
        "        return \"\", \"‚ùå No audio provided\"\n",
        "\n",
        "    try:\n",
        "        recognizer = sr.Recognizer()\n",
        "\n",
        "        # Handle different audio formats\n",
        "        audio_file = sr.AudioFile(audio_path)\n",
        "\n",
        "        with audio_file as source:\n",
        "            # Adjust for ambient noise\n",
        "            recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
        "            audio_data = recognizer.record(source)\n",
        "\n",
        "        # Try Google Speech Recognition\n",
        "        try:\n",
        "            text = recognizer.recognize_google(audio_data)\n",
        "            return text, f\"‚úÖ **Transcribed:** '{text}'\"\n",
        "        except sr.UnknownValueError:\n",
        "            return \"\", \"‚ùå Could not understand audio. Please speak clearly.\"\n",
        "        except sr.RequestError:\n",
        "            # Fallback to Sphinx if Google API fails\n",
        "            try:\n",
        "                text = recognizer.recognize_sphinx(audio_data)\n",
        "                return text, f\"‚úÖ **Transcribed (offline):** '{text}'\"\n",
        "            except:\n",
        "                return \"\", \"‚ùå Speech recognition service unavailable\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return \"\", f\"‚ùå Audio processing error: {str(e)}\"\n",
        "\n",
        "# ==================== CONTEXT RESOLUTION ====================\n",
        "def resolve_context(question: str) -> str:\n",
        "    \"\"\"Resolve references to previous queries\"\"\"\n",
        "    question_lower = question.lower()\n",
        "\n",
        "    # Check for contextual references\n",
        "    context_keywords = ['that', 'this', 'previous', 'last', 'it', 'them', 'those']\n",
        "    has_context = any(keyword in question_lower for keyword in context_keywords)\n",
        "\n",
        "    if not has_context:\n",
        "        return question\n",
        "\n",
        "    # Handle \"plot that/this/previous\"\n",
        "    if any(word in question_lower for word in ['plot', 'visualize', 'chart', 'graph']):\n",
        "        if result_cache['last_sql_result'] is not None:\n",
        "            return question  # Will be handled by PLOT agent\n",
        "\n",
        "    # Handle \"show reviews for that/previous\"\n",
        "    if 'review' in question_lower and has_context:\n",
        "        if result_cache['last_category']:\n",
        "            return f\"show reviews for {result_cache['last_category']} products\"\n",
        "        elif result_cache['last_product_ids']:\n",
        "            return question  # Will use cached product IDs\n",
        "\n",
        "    # Replace contextual references with actual entities\n",
        "    resolved = question\n",
        "    if result_cache['last_category']:\n",
        "        resolved = resolved.replace('that category', result_cache['last_category'])\n",
        "        resolved = resolved.replace('this category', result_cache['last_category'])\n",
        "\n",
        "    return resolved\n",
        "\n",
        "# ==================== DATE VALIDATION ====================\n",
        "def validate_date_range(question: str) -> Tuple[bool, Optional[str]]:\n",
        "    \"\"\"Check if question asks for data outside available range\"\"\"\n",
        "    years = re.findall(r'\\b(20\\d{2})\\b', question)\n",
        "\n",
        "    if not years:\n",
        "        return True, None\n",
        "\n",
        "    invalid_years = []\n",
        "    for year in years:\n",
        "        year_int = int(year)\n",
        "        if year_int < DATASET_START_YEAR or year_int > DATASET_END_YEAR:\n",
        "            invalid_years.append(year)\n",
        "\n",
        "    if invalid_years:\n",
        "        error_msg = f\"‚ùå **Data not available for year(s): {', '.join(invalid_years)}**\\n\\n\"\n",
        "        error_msg += f\"üìä {DATASET_INFO}\\n\\n\"\n",
        "        error_msg += f\"‚úÖ **Available years:** {DATASET_START_YEAR}-{DATASET_END_YEAR}\\n\\n\"\n",
        "        error_msg += f\"üí° **Try:** 'most sold product in 2017' or 'revenue in 2018'\"\n",
        "        return False, error_msg\n",
        "\n",
        "    return True, None\n",
        "\n",
        "# ==================== SAFE API CALL ====================\n",
        "def safe_api_call(prompt, max_tokens=500, temperature=0):\n",
        "    \"\"\"Make API call with rate limit checking\"\"\"\n",
        "    global api_calls_made\n",
        "\n",
        "    if api_calls_made >= MAX_API_CALLS:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(\n",
        "            prompt,\n",
        "            generation_config=genai.GenerationConfig(\n",
        "                temperature=temperature,\n",
        "                max_output_tokens=max_tokens\n",
        "            )\n",
        "        )\n",
        "        api_calls_made += 1\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        if \"429\" in str(e) or \"quota\" in str(e).lower():\n",
        "            return None\n",
        "        return None\n",
        "\n",
        "# ==================== RULE-BASED ROUTING ====================\n",
        "def rule_based_routing(question: str) -> list:\n",
        "    \"\"\"Enhanced rule-based routing with context awareness\"\"\"\n",
        "    question_lower = question.lower()\n",
        "\n",
        "    # Check for context references\n",
        "    if any(word in question_lower for word in ['previous', 'that', 'this', 'last']):\n",
        "        if 'plot' in question_lower or 'visualize' in question_lower:\n",
        "            return ['PLOT']\n",
        "        if 'review' in question_lower:\n",
        "            return ['RAG']\n",
        "\n",
        "    if any(word in question_lower for word in ['plot', 'graph', 'chart', 'visualize', 'show']):\n",
        "        return ['SQL', 'PLOT']\n",
        "\n",
        "    if any(word in question_lower for word in ['what is', 'explain', 'define', 'meaning of']):\n",
        "        return ['WEB', 'SQL', 'RAG']\n",
        "\n",
        "    if any(word in question_lower for word in ['review', 'feedback', 'customer', 'opinion']):\n",
        "        return ['SQL', 'RAG']\n",
        "\n",
        "    return ['SQL', 'RAG']\n",
        "\n",
        "def route_question(question: str) -> list:\n",
        "    \"\"\"Determines which agents to use\"\"\"\n",
        "    routing_prompt = f\"\"\"Analyze and determine agents:\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Agents: SQL, RAG, PLOT, WEB\n",
        "Return ONE LINE: \"SQL,RAG\" or \"SQL,PLOT\" etc.\n",
        "\n",
        "Response:\"\"\"\n",
        "\n",
        "    result = safe_api_call(routing_prompt, max_tokens=50)\n",
        "\n",
        "    if result is None:\n",
        "        return rule_based_routing(question)\n",
        "\n",
        "    try:\n",
        "        agents = result.upper().split(',')\n",
        "        agents = [a.strip() for a in agents if a.strip() in ['SQL', 'RAG', 'PLOT', 'WEB']]\n",
        "        return agents if agents else ['SQL', 'RAG']\n",
        "    except:\n",
        "        return rule_based_routing(question)\n",
        "\n",
        "# ==================== SQL GENERATION ====================\n",
        "def generate_sql_rule_based(question: str) -> str:\n",
        "    \"\"\"Generate SQL using patterns\"\"\"\n",
        "    question_lower = question.lower()\n",
        "\n",
        "    year_match = re.search(r'\\b(20\\d{2})\\b', question)\n",
        "    year = None\n",
        "    if year_match:\n",
        "        year_int = int(year_match.group(1))\n",
        "        if DATASET_START_YEAR <= year_int <= DATASET_END_YEAR:\n",
        "            year = year_match.group(1)\n",
        "\n",
        "    # Pattern: Average order value / average price\n",
        "    if 'average' in question_lower and ('order value' in question_lower or 'price' in question_lower):\n",
        "        category_match = re.search(r'(?:in|for|of)\\s+(?:the\\s+)?(\\w+(?:\\s+\\w+)?)\\s+category', question_lower)\n",
        "\n",
        "        if category_match:\n",
        "            category = category_match.group(1).strip()\n",
        "            where_clause = f\"WHERE t.product_category_name_english LIKE '%{category}%'\"\n",
        "        else:\n",
        "            where_clause = \"\"\n",
        "\n",
        "        return f\"\"\"SELECT AVG(oi.price) as average_order_value\n",
        "FROM olist_order_items_dataset oi\n",
        "JOIN olist_products_dataset p ON oi.product_id = p.product_id\n",
        "JOIN product_category_name_translation t ON p.product_category_name = t.product_category_name\n",
        "{where_clause}\"\"\"\n",
        "\n",
        "    if 'most sold' in question_lower or 'top sell' in question_lower or 'best sell' in question_lower:\n",
        "        where_clause = f\"WHERE strftime('%Y', o.order_purchase_timestamp) = '{year}'\" if year else \"\"\n",
        "        return f\"\"\"SELECT oi.product_id, COUNT(*) as sales_count, t.product_category_name_english, SUM(oi.price) as total_revenue\n",
        "FROM olist_order_items_dataset oi\n",
        "JOIN olist_orders_dataset o ON oi.order_id = o.order_id\n",
        "JOIN olist_products_dataset p ON oi.product_id = p.product_id\n",
        "JOIN product_category_name_translation t ON p.product_category_name = t.product_category_name\n",
        "{where_clause}\n",
        "GROUP BY oi.product_id, t.product_category_name_english\n",
        "ORDER BY sales_count DESC\n",
        "LIMIT 1\"\"\"\n",
        "\n",
        "    if 'revenue' in question_lower and 'category' in question_lower:\n",
        "        where_clause = f\"WHERE strftime('%Y', o.order_purchase_timestamp) = '{year}'\" if year else \"\"\n",
        "        return f\"\"\"SELECT t.product_category_name_english, COUNT(*) as sales_count, SUM(oi.price) as total_revenue\n",
        "FROM olist_order_items_dataset oi\n",
        "JOIN olist_orders_dataset o ON oi.order_id = o.order_id\n",
        "JOIN olist_products_dataset p ON oi.product_id = p.product_id\n",
        "JOIN product_category_name_translation t ON p.product_category_name = t.product_category_name\n",
        "{where_clause}\n",
        "GROUP BY t.product_category_name_english\n",
        "ORDER BY total_revenue DESC\n",
        "LIMIT 20\"\"\"\n",
        "\n",
        "    if 'seller' in question_lower and ('top' in question_lower or 'best' in question_lower):\n",
        "        limit = 25 if '25' in question else 10\n",
        "        return f\"\"\"SELECT seller_id, COUNT(*) as sales_frequency\n",
        "FROM olist_order_items_dataset\n",
        "GROUP BY seller_id\n",
        "ORDER BY sales_frequency DESC\n",
        "LIMIT {limit}\"\"\"\n",
        "\n",
        "    if 'top' in question_lower and 'product' in question_lower:\n",
        "        limit_match = re.search(r'\\b(\\d+)\\b', question)\n",
        "        limit = limit_match.group(1) if limit_match else 10\n",
        "        return f\"\"\"SELECT oi.product_id, COUNT(*) as sales_count, t.product_category_name_english\n",
        "FROM olist_order_items_dataset oi\n",
        "JOIN olist_products_dataset p ON oi.product_id = p.product_id\n",
        "JOIN product_category_name_translation t ON p.product_category_name = t.product_category_name\n",
        "GROUP BY oi.product_id, t.product_category_name_english\n",
        "ORDER BY sales_count DESC\n",
        "LIMIT {limit}\"\"\"\n",
        "\n",
        "    return \"Error: Could not generate SQL\"\n",
        "\n",
        "def generate_sql_from_question(question: str) -> str:\n",
        "    prompt = f\"\"\"Generate SQL:\n",
        "\n",
        "{SCHEMA_INFO}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Rules:\n",
        "- Start with SELECT, use exact columns\n",
        "- strftime('%Y', order_purchase_timestamp) for year\n",
        "- For category filtering, use product_category_name_english after joining with product_category_name_translation\n",
        "- Return complete query with all necessary JOINs\n",
        "\n",
        "SQL:\"\"\"\n",
        "\n",
        "    result = safe_api_call(prompt, max_tokens=600)\n",
        "\n",
        "    if result is None:\n",
        "        return generate_sql_rule_based(question)\n",
        "\n",
        "    lines = result.split('\\n')\n",
        "    clean_lines = []\n",
        "    found_select = False\n",
        "    for line in lines:\n",
        "        if 'SELECT' in line.upper() or found_select:\n",
        "            found_select = True\n",
        "            clean_lines.append(line)\n",
        "\n",
        "    sql = '\\n'.join(clean_lines).replace('```sql','').replace('```','').strip()\n",
        "    if sql.endswith(';'):\n",
        "        sql = sql[:-1]\n",
        "    return sql if sql else generate_sql_rule_based(question)\n",
        "\n",
        "# ==================== WEB SEARCH ====================\n",
        "def web_search_agent(question: str) -> str:\n",
        "    \"\"\"Search web\"\"\"\n",
        "    knowledge_base = {\n",
        "        \"bed bath table\": \"\"\"Bed, Bath & Table products include:\n",
        "- Bedding: sheets, pillowcases, comforters, duvets\n",
        "- Bath items: towels, bath mats, shower curtains\n",
        "- Table linens: tablecloths, placemats, napkins\n",
        "Common buyers: homeowners, newlyweds, renters\"\"\",\n",
        "\n",
        "        \"health beauty\": \"\"\"Health & Beauty products include:\n",
        "- Personal care: skincare, haircare, body care\n",
        "- Cosmetics: makeup, fragrances, nail care\n",
        "- Health: vitamins, supplements, medical supplies\n",
        "Popular with: all demographics, especially women 18-45\"\"\"\n",
        "    }\n",
        "\n",
        "    question_lower = question.lower()\n",
        "    for key, answer in knowledge_base.items():\n",
        "        if key in question_lower:\n",
        "            return answer\n",
        "\n",
        "    result = safe_api_call(f\"Briefly explain: {question}\", max_tokens=300)\n",
        "    return result if result else \"Web search unavailable (rate limit)\"\n",
        "\n",
        "# ==================== PLOTTING ====================\n",
        "def plotting_agent(question: str, data: pd.DataFrame = None) -> Optional[str]:\n",
        "    \"\"\"Create visualizations with cache support\"\"\"\n",
        "\n",
        "    if data is None:\n",
        "        data = result_cache['last_sql_result']\n",
        "\n",
        "    if data is None or len(data) == 0:\n",
        "        return None\n",
        "\n",
        "    df = data.head(50)\n",
        "    cols = list(df.columns)\n",
        "\n",
        "    plot_type = 'bar'\n",
        "    if 'time' in question.lower() or 'trend' in question.lower():\n",
        "        plot_type = 'line'\n",
        "    elif 'pie' in question.lower() or 'proportion' in question.lower():\n",
        "        plot_type = 'pie'\n",
        "\n",
        "    y_col = None\n",
        "    x_col = None\n",
        "\n",
        "    for col in cols:\n",
        "        if df[col].dtype in ['int64', 'float64']:\n",
        "            if 'count' in col.lower() or 'frequency' in col.lower() or 'revenue' in col.lower():\n",
        "                y_col = col\n",
        "                break\n",
        "\n",
        "    if y_col is None:\n",
        "        for col in cols:\n",
        "            if df[col].dtype in ['int64', 'float64']:\n",
        "                y_col = col\n",
        "                break\n",
        "\n",
        "    for col in cols:\n",
        "        if col != y_col and (df[col].dtype == 'object' or col.endswith('_id')):\n",
        "            x_col = col\n",
        "            break\n",
        "\n",
        "    if x_col is None:\n",
        "        x_col = cols[0]\n",
        "\n",
        "    try:\n",
        "        plt.figure(figsize=(14, 7))\n",
        "\n",
        "        if plot_type == 'bar':\n",
        "            x_data = df[x_col]\n",
        "            y_data = df[y_col] if y_col else df.iloc[:, -1]\n",
        "\n",
        "            if df[x_col].dtype == 'object':\n",
        "                x_labels = [str(x)[:15] + '...' if len(str(x)) > 15 else str(x) for x in x_data]\n",
        "            else:\n",
        "                x_labels = x_data\n",
        "\n",
        "            plt.bar(range(len(y_data)), y_data, color='steelblue', alpha=0.8)\n",
        "            plt.xticks(range(len(y_data)), x_labels, rotation=45, ha='right')\n",
        "            plt.xlabel(x_col)\n",
        "            plt.ylabel(y_col if y_col else 'Value')\n",
        "\n",
        "        elif plot_type == 'line':\n",
        "            y_data = df[y_col] if y_col else df.iloc[:, -1]\n",
        "            plt.plot(range(len(df)), y_data, marker='o', linewidth=2, markersize=6)\n",
        "            plt.xlabel('Index')\n",
        "            plt.ylabel(y_col if y_col else 'Value')\n",
        "\n",
        "        elif plot_type == 'pie':\n",
        "            labels = [str(x)[:20] for x in df[x_col].head(10)]\n",
        "            values = df[y_col].head(10) if y_col else df.iloc[:10, -1]\n",
        "            plt.pie(values, labels=labels, autopct='%1.1f%%', startangle=90)\n",
        "            plt.axis('equal')\n",
        "\n",
        "        title = f\"{y_col if y_col else 'Data'} by {x_col}\"\n",
        "        plt.title(title, fontsize=14, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        plot_filename = f\"/content/plot_{int(time.time())}.png\"\n",
        "        plt.savefig(plot_filename, dpi=150, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        result_cache['last_plot_path'] = plot_filename\n",
        "        return plot_filename\n",
        "\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "# ==================== ENHANCED RAG SEARCH ====================\n",
        "def search_reviews_by_category(category: str, k: int = 5) -> str:\n",
        "    \"\"\"Fuzzy search reviews by category name\"\"\"\n",
        "    if not vectorstores:\n",
        "        return \"\"\n",
        "\n",
        "    try:\n",
        "        # First, get products in this category\n",
        "        conn = sqlite3.connect(sqlite_path)\n",
        "        query = f\"\"\"\n",
        "        SELECT DISTINCT oi.product_id\n",
        "        FROM olist_order_items_dataset oi\n",
        "        JOIN olist_products_dataset p ON oi.product_id = p.product_id\n",
        "        JOIN product_category_name_translation t ON p.product_category_name = t.product_category_name\n",
        "        WHERE t.product_category_name_english LIKE '%{category}%'\n",
        "        LIMIT 20\n",
        "        \"\"\"\n",
        "        df = pd.read_sql_query(query, conn)\n",
        "        conn.close()\n",
        "\n",
        "        if len(df) > 0:\n",
        "            return search_reviews_by_product_ids(df['product_id'].tolist(), k=k)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Fallback: direct semantic search\n",
        "    if \"olist_order_reviews_dataset\" in vectorstores:\n",
        "        try:\n",
        "            vs = vectorstores[\"olist_order_reviews_dataset\"]\n",
        "            docs = vs.similarity_search(f\"{category} product review\", k=k)\n",
        "            results = []\n",
        "            for i, doc in enumerate(docs, 1):\n",
        "                score = doc.metadata.get('review_score', 'N/A')\n",
        "                content = doc.page_content[:250].strip()\n",
        "                results.append(f\"**Review {i}** (Score: {score}/5)\\n{content}...\")\n",
        "            return \"\\n\\n\".join(results)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "def search_reviews_by_order_ids(order_ids: list, k: int = 5) -> str:\n",
        "    \"\"\"Search reviews by order IDs\"\"\"\n",
        "    if not vectorstores or \"olist_order_reviews_dataset\" not in vectorstores:\n",
        "        return \"\"\n",
        "\n",
        "    vs = vectorstores[\"olist_order_reviews_dataset\"]\n",
        "    all_docs = []\n",
        "\n",
        "    for order_id in order_ids[:5]:\n",
        "        try:\n",
        "            docs = vs.similarity_search(str(order_id), k=2)\n",
        "            for doc in docs:\n",
        "                if doc.metadata.get('order_id') == order_id:\n",
        "                    all_docs.append(doc)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    if not all_docs:\n",
        "        try:\n",
        "            all_docs = vs.similarity_search(\"customer review feedback\", k=k)\n",
        "        except:\n",
        "            return \"\"\n",
        "\n",
        "    results = []\n",
        "    for i, doc in enumerate(all_docs[:k], 1):\n",
        "        score = doc.metadata.get('review_score', 'N/A')\n",
        "        content = doc.page_content[:250].strip()\n",
        "        results.append(f\"**Review {i}** (Score: {score}/5)\\n{content}...\")\n",
        "\n",
        "    return \"\\n\\n\".join(results)\n",
        "\n",
        "def search_reviews_by_product_ids(product_ids: list, k: int = 5) -> str:\n",
        "    \"\"\"Search reviews by product IDs\"\"\"\n",
        "    if not vectorstores:\n",
        "        return \"\"\n",
        "\n",
        "    try:\n",
        "        conn = sqlite3.connect(sqlite_path)\n",
        "        product_ids_str = \"','\".join([str(pid) for pid in product_ids[:5]])\n",
        "        query = f\"\"\"\n",
        "        SELECT DISTINCT o.order_id\n",
        "        FROM olist_order_items_dataset o\n",
        "        WHERE o.product_id IN ('{product_ids_str}')\n",
        "        LIMIT 15\n",
        "        \"\"\"\n",
        "        df = pd.read_sql_query(query, conn)\n",
        "        conn.close()\n",
        "\n",
        "        if len(df) > 0:\n",
        "            return search_reviews_by_order_ids(df['order_id'].tolist(), k=k)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "# ==================== UPDATE CACHE ====================\n",
        "def update_result_cache(question: str, sql_result: pd.DataFrame, sql_query: str):\n",
        "    \"\"\"Update result cache with latest query info\"\"\"\n",
        "    result_cache['last_sql_result'] = sql_result\n",
        "    result_cache['last_sql_query'] = sql_query\n",
        "    result_cache['last_question'] = question\n",
        "\n",
        "    # Extract useful metadata\n",
        "    if sql_result is not None and len(sql_result) > 0:\n",
        "        if 'product_id' in sql_result.columns:\n",
        "            result_cache['last_product_ids'] = sql_result['product_id'].tolist()[:20]\n",
        "\n",
        "        if 'order_id' in sql_result.columns:\n",
        "            result_cache['last_order_ids'] = sql_result['order_id'].tolist()[:20]\n",
        "\n",
        "        if 'product_category_name_english' in sql_result.columns:\n",
        "            result_cache['last_category'] = sql_result['product_category_name_english'].iloc[0]\n",
        "\n",
        "    # Store in query history (keep last 5)\n",
        "    result_cache['query_history'].append({\n",
        "        'question': question,\n",
        "        'timestamp': datetime.now().strftime('%H:%M:%S'),\n",
        "        'has_result': sql_result is not None\n",
        "    })\n",
        "    if len(result_cache['query_history']) > 5:\n",
        "        result_cache['query_history'].pop(0)\n",
        "\n",
        "# ==================== MAIN PROCESSING FUNCTION ====================\n",
        "def process_question(question: str, history: list, audio_input=None) -> Tuple[str, Optional[str], str, str]:\n",
        "    \"\"\"Process question (text or voice) and return answer, plot, SQL, and transcription\"\"\"\n",
        "\n",
        "    transcription_msg = \"\"\n",
        "\n",
        "    # Handle voice input\n",
        "    if audio_input is not None:\n",
        "        transcribed_text, trans_msg = transcribe_audio(audio_input)\n",
        "        transcription_msg = trans_msg\n",
        "        if transcribed_text:\n",
        "            question = transcribed_text\n",
        "        else:\n",
        "            return trans_msg, None, \"\", trans_msg\n",
        "\n",
        "    if not question.strip():\n",
        "        return \"Please enter a question or record audio.\", None, \"\", transcription_msg\n",
        "\n",
        "    # Resolve contextual references\n",
        "    original_question = question\n",
        "    question = resolve_context(question)\n",
        "\n",
        "    if original_question != question:\n",
        "        transcription_msg += f\"\\n\\nüîÑ **Resolved to:** {question}\"\n",
        "\n",
        "    # Validate date range\n",
        "    is_valid, error_msg = validate_date_range(question)\n",
        "    if not is_valid:\n",
        "        return error_msg, None, \"\", transcription_msg\n",
        "\n",
        "    # Route to agents\n",
        "    agents = route_question(question)\n",
        "\n",
        "    status = f\"ü§ñ **Agents:** {' ‚Üí '.join(agents)}\\n\\n\"\n",
        "\n",
        "    web_result = \"\"\n",
        "    sql_result = \"\"\n",
        "    rag_results = \"\"\n",
        "    plot_path = None\n",
        "    sql_query = \"\"\n",
        "    df = None\n",
        "\n",
        "    # Execute agents\n",
        "    for agent in agents:\n",
        "        if agent == 'WEB':\n",
        "            web_result = web_search_agent(question)\n",
        "            status += f\"üåê **Web Search:** Completed\\n\"\n",
        "\n",
        "        elif agent == 'SQL':\n",
        "            status += f\"üìä **SQL Agent:** Generating query...\\n\"\n",
        "            sql = generate_sql_from_question(question)\n",
        "\n",
        "            if sql.startswith(\"Error\"):\n",
        "                status += f\"‚ùå {sql}\\n\"\n",
        "                continue\n",
        "\n",
        "            sql_query = sql\n",
        "            status += f\"‚öôÔ∏è **SQL Agent:** Executing query...\\n\"\n",
        "\n",
        "            try:\n",
        "                conn = sqlite3.connect(sqlite_path)\n",
        "                df = pd.read_sql_query(sql, conn)\n",
        "                conn.close()\n",
        "\n",
        "                if len(df) == 0:\n",
        "                    status += f\"‚ö†Ô∏è No results found\\n\"\n",
        "                    continue\n",
        "\n",
        "                # Update cache\n",
        "                update_result_cache(question, df, sql_query)\n",
        "\n",
        "                # Format SQL result\n",
        "                if len(df.columns) == 1 and len(df) == 1:\n",
        "                    col_name = df.columns[0]\n",
        "                    value = df.iloc[0, 0]\n",
        "                    if pd.notna(value):\n",
        "                        if isinstance(value, float):\n",
        "                            sql_result = f\"**{col_name}:** ${value:.2f}\" if 'price' in col_name.lower() or 'revenue' in col_name.lower() else f\"**{col_name}:** {value:.2f}\"\n",
        "                        else:\n",
        "                            sql_result = f\"**{col_name}:** {value}\"\n",
        "                    else:\n",
        "                        sql_result = f\"**{col_name}:** No data available\"\n",
        "                else:\n",
        "                    sql_result = df.head(20).to_markdown(index=False)\n",
        "\n",
        "                status += f\"‚úÖ **SQL Agent:** Found {len(df)} rows\\n\"\n",
        "\n",
        "            except Exception as e:\n",
        "                status += f\"‚ùå **SQL Error:** {str(e)}\\n\"\n",
        "                continue\n",
        "\n",
        "        elif agent == 'RAG':\n",
        "            status += f\"üîç **RAG Agent:** Searching reviews...\\n\"\n",
        "\n",
        "            # Use cached data if available\n",
        "            if result_cache['last_product_ids']:\n",
        "                rag_results = search_reviews_by_product_ids(result_cache['last_product_ids'], k=5)\n",
        "            elif result_cache['last_order_ids']:\n",
        "                rag_results = search_reviews_by_order_ids(result_cache['last_order_ids'], k=5)\n",
        "            elif result_cache['last_category']:\n",
        "                rag_results = search_reviews_by_category(result_cache['last_category'], k=5)\n",
        "            elif df is not None and len(df) > 0:\n",
        "                if 'product_id' in df.columns:\n",
        "                    product_ids = df['product_id'].tolist()\n",
        "                    rag_results = search_reviews_by_product_ids(product_ids, k=5)\n",
        "                elif 'order_id' in df.columns:\n",
        "                    order_ids = df['order_id'].tolist()\n",
        "                    rag_results = search_reviews_by_order_ids(order_ids, k=5)\n",
        "\n",
        "            if rag_results:\n",
        "                status += f\"‚úÖ **RAG Agent:** Found reviews\\n\"\n",
        "            else:\n",
        "                status += f\"‚ö†Ô∏è **RAG Agent:** No reviews found\\n\"\n",
        "\n",
        "        elif agent == 'PLOT':\n",
        "            status += f\"üìà **Plot Agent:** Creating visualization...\\n\"\n",
        "            plot_path = plotting_agent(question)\n",
        "            if plot_path:\n",
        "                status += f\"‚úÖ **Plot Agent:** Chart created\\n\"\n",
        "            else:\n",
        "                status += f\"‚ö†Ô∏è **Plot Agent:** Could not create plot\\n\"\n",
        "\n",
        "    # Generate answer\n",
        "    if not any([web_result, sql_result, rag_results]):\n",
        "        return status + \"\\n‚ùå No results from any agent\", None, sql_query, transcription_msg\n",
        "\n",
        "    answer_prompt = f\"\"\"Synthesize this data:\n",
        "\n",
        "Question: {question}\n",
        "{'Web: ' + web_result[:500] if web_result else ''}\n",
        "{'SQL: ' + sql_result[:1000] if sql_result else ''}\n",
        "{'Reviews: ' + rag_results[:500] if rag_results else ''}\n",
        "\n",
        "Provide clear insights:\"\"\"\n",
        "\n",
        "    answer = safe_api_call(answer_prompt, max_tokens=500, temperature=0.3)\n",
        "\n",
        "    if answer is None:\n",
        "        answer = \"**Results Summary:**\\n\\n\"\n",
        "        if sql_result:\n",
        "            answer += f\"üìä **Query Result:**\\n\\n{sql_result}\\n\\n\"\n",
        "        if rag_results:\n",
        "            answer += f\"üìÑ **Customer Reviews:**\\n{rag_results[:500]}\\n\\n\"\n",
        "        if web_result:\n",
        "            answer += f\"üåê **Web Info:**\\n{web_result[:300]}\\n\\n\"\n",
        "        answer += f\"\\n\\n_(API rate limit reached. Showing raw results. Calls: {api_calls_made}/{MAX_API_CALLS})_\"\n",
        "\n",
        "    # Build final output\n",
        "    final_output = status + \"\\n---\\n\\n## üìù Answer\\n\\n\" + answer\n",
        "\n",
        "    if sql_result and not sql_result.startswith(\"**\"):\n",
        "        final_output += f\"\\n\\n---\\n\\n## üìä Data Preview\\n\\n{sql_result}\"\n",
        "\n",
        "    if rag_results:\n",
        "        final_output += f\"\\n\\n---\\n\\n## üí¨ Customer Reviews\\n\\n{rag_results[:500]}\"\n",
        "\n",
        "    return final_output, plot_path, sql_query, transcription_msg\n",
        "\n",
        "# ==================== GRADIO INTERFACE ====================\n",
        "def create_ui():\n",
        "    with gr.Blocks(theme=gr.themes.Soft(), title=\"Multi-Agent E-commerce Analytics\") as demo:\n",
        "        gr.Markdown(\"\"\"\n",
        "        # üöÄ Multi-Agent E-commerce Analytics System\n",
        "        ### Brazilian Olist Dataset (2016-2018) | 100k+ Orders | üé§ Voice Enabled\n",
        "\n",
        "        **Available Agents:** SQL üìä | RAG üìÑ | PLOT üìà | WEB üåê | VOICE üé§\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=2):\n",
        "                # Voice input\n",
        "                with gr.Group():\n",
        "                    gr.Markdown(\"### üé§ Voice Input (Optional)\")\n",
        "                    audio_input = gr.Audio(\n",
        "                        sources=[\"microphone\"],\n",
        "                        type=\"filepath\",\n",
        "                        label=\"Record Your Question\",\n",
        "                        show_label=False\n",
        "                    )\n",
        "                    transcription_output = gr.Markdown(value=\"\", label=\"Transcription\")\n",
        "\n",
        "                # Text input\n",
        "                with gr.Group():\n",
        "                    gr.Markdown(\"### üí¨ Text Input\")\n",
        "                    question_input = gr.Textbox(\n",
        "                        label=\"Ask a Question\",\n",
        "                        placeholder=\"e.g., 'Top 5 selling products in 2017' or 'plot that' or 'show reviews for previous'\",\n",
        "                        lines=2\n",
        "                    )\n",
        "\n",
        "                with gr.Row():\n",
        "                    submit_btn = gr.Button(\"üîç Analyze\", variant=\"primary\", scale=2)\n",
        "                    clear_btn = gr.Button(\"üóëÔ∏è Clear\", scale=1)\n",
        "\n",
        "                gr.Markdown(\"\"\"\n",
        "                ### üí° Example Queries:\n",
        "                **Basic Queries:**\n",
        "                - `Top selling product in 2017`\n",
        "                - `Revenue by category in 2018 and plot it`\n",
        "                - `Average order value for electronics category`\n",
        "\n",
        "                **Contextual Queries (using cache):**\n",
        "                - `plot that` _(plots previous SQL result)_\n",
        "                - `show reviews for that` _(shows reviews for previous category)_\n",
        "                - `visualize the previous data`\n",
        "\n",
        "                **Category Queries:**\n",
        "                - `What is bed bath table category?`\n",
        "                - `Customer reviews for health_beauty products`\n",
        "                - `Top 25 sellers and visualize`\n",
        "\n",
        "                **üé§ Voice Commands:**\n",
        "                - Click microphone and speak naturally\n",
        "                - Example: \"Show me top products in twenty seventeen\"\n",
        "                \"\"\")\n",
        "\n",
        "            with gr.Column(scale=1):\n",
        "                api_status = gr.Markdown(f\"**API Usage:** 0/{MAX_API_CALLS}\")\n",
        "                dataset_info = gr.Markdown(f\"**Dataset:** {DATASET_INFO}\")\n",
        "\n",
        "                with gr.Accordion(\"üìã Query History\", open=False):\n",
        "                    history_display = gr.Markdown(\"No queries yet\")\n",
        "\n",
        "                cache_status = gr.Markdown(\"**Cache:** Empty\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=3):\n",
        "                answer_output = gr.Markdown(label=\"Analysis Results\", value=\"\")\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                plot_output = gr.Image(label=\"Visualization\", type=\"filepath\")\n",
        "\n",
        "        with gr.Accordion(\"üîß SQL Query (Generated)\", open=False):\n",
        "            sql_output = gr.Code(label=\"SQL Query\", language=\"sql\")\n",
        "\n",
        "        with gr.Accordion(\"üìö Help & Information\", open=False):\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### ü§ñ Agent Capabilities:\n",
        "\n",
        "            **VOICE Agent üé§** _(NEW!)_\n",
        "            - Speech-to-text transcription\n",
        "            - Supports natural voice commands\n",
        "            - Works with Google Speech Recognition\n",
        "            - Fallback to offline recognition\n",
        "\n",
        "            **SQL Agent üìä**\n",
        "            - Query database for sales, products, orders, customers\n",
        "            - Automatically generates SQL from natural language\n",
        "            - Supports date filtering (2016-2018)\n",
        "            - **Cache support:** Results stored for follow-up queries\n",
        "\n",
        "            **RAG Agent üìÑ** _(ENHANCED!)_\n",
        "            - Search customer reviews\n",
        "            - Find product feedback by category\n",
        "            - Fuzzy search by keywords\n",
        "            - Uses cached product/order IDs for context\n",
        "\n",
        "            **Plot Agent üìà** _(IMPROVED!)_\n",
        "            - Create bar charts, line graphs, pie charts\n",
        "            - Automatic visualization type selection\n",
        "            - **Works with cached results** - say \"plot that\"\n",
        "            - No need to re-run SQL queries\n",
        "\n",
        "            **Web Agent üåê**\n",
        "            - Explain product categories\n",
        "            - Provide general knowledge\n",
        "            - Define terms\n",
        "\n",
        "            ### üÜï New Features:\n",
        "\n",
        "            **1. Voice Input**\n",
        "            - Click microphone icon to record\n",
        "            - Speak your question naturally\n",
        "            - Automatic transcription to text\n",
        "            - Works with all agent types\n",
        "\n",
        "            **2. Enhanced Caching**\n",
        "            - Previous SQL results stored automatically\n",
        "            - Say \"plot that\" to visualize last query\n",
        "            - Say \"show reviews for previous\" for context\n",
        "            - Maintains last 5 query history\n",
        "\n",
        "            **3. Better Review Mapping**\n",
        "            - Fuzzy search by category name\n",
        "            - Keyword-based review search\n",
        "            - No need for exact product IDs\n",
        "\n",
        "            **4. Context Resolution**\n",
        "            - Understands \"that\", \"previous\", \"last\"\n",
        "            - Automatically resolves references\n",
        "            - Seamless follow-up questions\n",
        "\n",
        "            ### ‚ö†Ô∏è Important Notes:\n",
        "            - Dataset covers 2016-2018 only\n",
        "            - Queries outside this range will be rejected\n",
        "            - API rate limit: 180 calls per session\n",
        "            - Voice recognition requires microphone access\n",
        "            - Cache persists during session only\n",
        "            \"\"\")\n",
        "\n",
        "        def update_status():\n",
        "            status = f\"**API Usage:** {api_calls_made}/{MAX_API_CALLS}\"\n",
        "\n",
        "            # Update history\n",
        "            history_text = \"**Recent Queries:**\\n\\n\"\n",
        "            if result_cache['query_history']:\n",
        "                for i, q in enumerate(reversed(result_cache['query_history']), 1):\n",
        "                    emoji = \"‚úÖ\" if q['has_result'] else \"‚ùå\"\n",
        "                    history_text += f\"{i}. {emoji} [{q['timestamp']}] {q['question'][:50]}...\\n\"\n",
        "            else:\n",
        "                history_text = \"No queries yet\"\n",
        "\n",
        "            # Update cache status - FIXED: Check for None and empty DataFrame properly\n",
        "            cache_text = \"**Cache Status:**\\n\\n\"\n",
        "            has_cache_items = False\n",
        "\n",
        "            if result_cache['last_sql_result'] is not None and not result_cache['last_sql_result'].empty:\n",
        "                cache_text += f\"‚úÖ SQL Result: {len(result_cache['last_sql_result'])} rows\\n\"\n",
        "                has_cache_items = True\n",
        "\n",
        "            if result_cache['last_plot_path']:\n",
        "                cache_text += f\"‚úÖ Plot: Available\\n\"\n",
        "                has_cache_items = True\n",
        "\n",
        "            if result_cache['last_category']:\n",
        "                cache_text += f\"‚úÖ Category: {result_cache['last_category']}\\n\"\n",
        "                has_cache_items = True\n",
        "\n",
        "            if result_cache['last_product_ids']:\n",
        "                cache_text += f\"‚úÖ Products: {len(result_cache['last_product_ids'])} IDs\\n\"\n",
        "                has_cache_items = True\n",
        "\n",
        "            if not has_cache_items:\n",
        "                cache_text += \"Empty\"\n",
        "\n",
        "            return status, history_text, cache_text\n",
        "\n",
        "        def submit_question(question, audio):\n",
        "            answer, plot, sql, transcription = process_question(question, [], audio)\n",
        "            status, history, cache = update_status()\n",
        "            return answer, plot, sql, status, history, cache, transcription\n",
        "\n",
        "        def clear_all():\n",
        "            global result_cache\n",
        "            result_cache = {\n",
        "                'last_sql_result': None,\n",
        "                'last_plot_path': None,\n",
        "                'last_sql_query': None,\n",
        "                'last_question': None,\n",
        "                'last_product_ids': [],\n",
        "                'last_order_ids': [],\n",
        "                'last_category': None,\n",
        "                'query_history': []\n",
        "            }\n",
        "            status, history, cache = update_status()\n",
        "            return \"\", None, \"\", status, history, cache, \"\"\n",
        "\n",
        "        submit_btn.click(\n",
        "            fn=submit_question,\n",
        "            inputs=[question_input, audio_input],\n",
        "            outputs=[answer_output, plot_output, sql_output, api_status,\n",
        "                    history_display, cache_status, transcription_output]\n",
        "        )\n",
        "\n",
        "        question_input.submit(\n",
        "            fn=submit_question,\n",
        "            inputs=[question_input, audio_input],\n",
        "            outputs=[answer_output, plot_output, sql_output, api_status,\n",
        "                    history_display, cache_status, transcription_output]\n",
        "        )\n",
        "\n",
        "        clear_btn.click(\n",
        "            fn=clear_all,\n",
        "            inputs=[],\n",
        "            outputs=[answer_output, plot_output, sql_output, api_status,\n",
        "                    history_display, cache_status, transcription_output]\n",
        "        )\n",
        "\n",
        "    return demo\n",
        "\n",
        "# ==================== LAUNCH ====================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üöÄ Initializing Enhanced Multi-Agent System...\")\n",
        "    print(f\"‚úÖ Database: Connected\")\n",
        "    print(f\"‚úÖ ChromaDB: {len(vectorstores) if vectorstores else 0} collections\")\n",
        "    print(f\"‚úÖ Gemini API: Ready\")\n",
        "    print(f\"‚úÖ Voice Recognition: Ready\")\n",
        "    print(f\"üìÖ Dataset: {DATASET_INFO}\")\n",
        "    print(f\"üÜï New Features: Voice Input, Enhanced Caching, Context Resolution\")\n",
        "    print(\"\\nüåê Launching Gradio UI...\")\n",
        "\n",
        "    demo = create_ui()\n",
        "    demo.launch(\n",
        "        share=True,\n",
        "        debug=True,\n",
        "        server_port=7860\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
